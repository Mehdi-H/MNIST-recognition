{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "level": 1,
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Necessary-installs\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Necessary installs</a></div><div class=\"lev1\"><a href=\"#Context\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Context</a></div><div class=\"lev1\"><a href=\"#Let's-code-!\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Let's code !</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "level": 1
   },
   "source": [
    "# Necessary installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "level": 7
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "level": 7
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow available in python 3.5 environment !\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tensorflow\n",
    "    print(\"tensorflow available in python 3.5 environment !\")\n",
    "except Exception as e:\n",
    "    print(\"You need python 3.5 and to install the tensorflow library to continue !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "level": 7
   },
   "source": [
    "Using Conda, you can do as follow if you got the error :\n",
    "\n",
    "- Create a python 3.5 env and jupyter kernel with conda :\n",
    "```\n",
    "conda create -n py35 python=3.5\n",
    "source activate py35\n",
    "conda install notebook ipykernel\n",
    "ipython kernel install --user --name=python3.5\n",
    "```\n",
    "\n",
    "- Install tensorflow with pip :\n",
    "```\n",
    "pip install tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "level": 1
   },
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "[TensorFlow tutorial](https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html#mnist-for-ml-beginners) using MNIST dataset to recognize handwritten digits automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "The MNIST data is hosted on [Yann LeCun's website](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "We can download it easily (or read it if already downloaded) as follow :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "level": 7
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "The MNIST data is split into three parts.\n",
    "\n",
    "- A training set, so that our net architecture can learn from this data,\n",
    "- A validation set to configure its hyperparameter,\n",
    "- A test set to try and predict the digit labels from its image on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "**mnist.train.images** is a tensor (an n-dimensional array) with a shape of [55000, 784]. The first dimension is an index into the list of images and the second dimension is the index for each pixel in each image. Each entry in the tensor is a pixel intensity between 0 and 1, for a particular pixel in a particular image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "level": 1
   },
   "source": [
    "# Let's code !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "TensorFlow lets us describe interacting operations by manipulating symbolic variables, like this :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "**x** isn't a specific value. It's a **placeholder**, a value that we'll input when we ask TensorFlow to run a computation. We want to be able to input any number of MNIST images, each flattened into a 784-dimensional vector. We represent this as a 2-D tensor of floating-point numbers, with a shape [None, 784]. (Here **None** means that a dimension can be of any length.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "We also need the **weights** and **biases** for our model. We could imagine treating these like additional inputs, but TensorFlow has an even better way to handle it: **Variable**. A Variable is a modifiable tensor that lives in TensorFlow's graph of interacting operations. It can be used and even modified by the computation. For machine learning applications, one generally has the model parameters be Variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "W has a shape of [784, 10] because we want to multiply the 784-dimensional image vectors by it to produce 10-dimensional vectors of evidence for the difference classes. b has a shape of [10] so we can add it to the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "Our model can now be implemented in only one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "Now, this model needs to be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "To train our model, we need to define a way to labelize it as good or bad. One way to do it is through the **cross-entropy** function. It describes how inefficient our predictions are for describing the truth.\n",
    "\n",
    "We first need a placeholder to compute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "Then we can implement the cross-entropy function, $-\\sum\\limits y'log(y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "First, tf.log computes the logarithm of each element of y. Next, we multiply each element of y_ with the corresponding element of tf.log(y). Then tf.reduce_sum adds the elements in the second dimension of y, due to the reduction_indices=[1] parameter. Finally, tf.reduce_mean computes the mean over all the examples in the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "level": 7
   },
   "source": [
    "Note that in the source code, we don't use this formulation, because it is numerically unstable. Instead, we apply tf.nn.softmax_cross_entropy_with_logits on the unnormalized logits (e.g., we call softmax_cross_entropy_with_logits on tf.matmul(x, W) + b), because this more numerically stable function internally computes the softmax activation. In your code, consider using tf.nn.softmax_cross_entropy_with_logits instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
